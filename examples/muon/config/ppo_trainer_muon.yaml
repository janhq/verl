# Example PPO training config using Muon optimizer
#
# To use Muon optimizer, change the optimizer config from:
#   - ../optim@optim: fsdp
# to:
#   - ../optim@optim: muon

# specify the default per-component configs
defaults:

  # Actor config with Muon optimizer
  - actor@actor_rollout_ref.actor: dp_actor

  # Change this to use Muon optimizer instead of default fsdp (AdamW)
  - ../optim@optim: muon

  - data@data: legacy_data
  - reward_manager@reward_manager
  - ref@actor_rollout_ref.ref: dp_ref
  - rollout@actor_rollout_ref.rollout: rollout
  - model@actor_rollout_ref.model: hf_model
  - critic@critic: dp_critic
  - reward_model@reward_model: dp_reward_loop
  - algorithm@algorithm.rollout_correction: rollout_correction
  - _self_

# config for actor, rollout and reference model
actor_rollout_ref:

  hybrid_engine: true
  nccl_timeout: 600

  rollout:
    layered_summon: False

# custom reward function definition
custom_reward_function:
  path: null
  name: compute_score

# config for the algorithm
algorithm:
  _target_: verl.trainer.config.AlgoConfig
  gamma: 1.0
  lam: 1.0
  adv_estimator: gae
  norm_adv_by_std_in_grpo: True
  use_kl_in_reward: False
  kl_penalty: kl
  kl_ctrl:
    _target_: verl.trainer.config.KLControlConfig
    type: fixed
    kl_coef: 0.001
  horizon: 10000
  target_kl: 0.1
  use_pf_ppo: False
  pf_ppo:
    reweight_method: pow
    weight_pow: 2.0

# config for the trainer
trainer:
  balance_batch: True
  total_epochs: 30
  total_training_steps: null
  project_name: verl_examples
  experiment_name: muon_ppo_example
  logger: ["console", "wandb"]
  log_val_generations: 0
  rollout_data_dir: null
  validation_data_dir: null
  nnodes: 1
  n_gpus_per_node: 8
  save_freq: -1
  esi_redundant_time: 0
  resume_mode: auto
  resume_from_path: null
  val_before_train: True
  val_only: False
  test_freq: -1
  critic_warmup: 0
  default_hdfs_dir: null
  del_local_ckpt_after_load: False
  default_local_dir: checkpoints/${trainer.project_name}/${trainer.experiment_name}
  max_actor_ckpt_to_keep: null
  max_critic_ckpt_to_keep: null
  ray_wait_register_center_timeout: 300
  device: cuda
  use_legacy_worker_impl: auto

# profiler configs
global_profiler:
  _target_: verl.utils.profiler.ProfilerConfig
  tool: null
  steps: null
  profile_continuous_steps: False
  save_path: "outputs/profile"
  global_tool_config:
    nsys:
      _target_: verl.utils.profiler.config.NsightToolConfig
      discrete: False
      controller_nsight_options:
        trace: "cuda,nvtx,cublas,ucx"
        cuda-memory-usage: "true"
        cuda-graph-trace: "graph"
      worker_nsight_options:
        trace: "cuda,nvtx,cublas,ucx"
        cuda-memory-usage: "true"
        cuda-graph-trace: "graph"
        capture-range: "cudaProfilerApi"
        capture-range-end: null
        kill: none
    torch_memory:
      trace_alloc_max_entries: 100_000
      stack_depth: 32
      context: "all"
      stacks: "all"
      kw_args: {}

transfer_queue:
  enable: False

ray_kwargs:
  ray_init:
    num_cpus: null
  timeline_json_file: null